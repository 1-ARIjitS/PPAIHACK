{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers torch torchvision"
      ],
      "metadata": {
        "id": "lDHSt0Tyf1bK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756ab2da-bd13-4415-dafb-e27c09d3bf90"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from datasets import load_dataset\n",
        "from torchvision import transforms\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from safetensors.torch import save_file\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "5qQIsf8jfwo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSRZN8YWmFNw",
        "outputId": "1f609c8c-f990-4833-a2ad-b1d63ba24554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-18a5c652257b>:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"JLB-JLB/seizure_eeg_dev\")\n",
        "\n",
        "# Custom dataset class\n",
        "class SeizureEEGDataset(Dataset):\n",
        "    def __init__(self, hf_dataset, split='train', transform=None):\n",
        "        self.data = hf_dataset[split]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]['image']\n",
        "        if image.mode != 'L':\n",
        "            image = image.convert('L')\n",
        "        label = self.data[idx]['label']\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sACabCenf1Fx",
        "outputId": "91562efb-1802-4011-f8dd-8fb0e61528f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "LwGnUEocgBMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "full_dataset = SeizureEEGDataset(dataset, split='train', transform=transform)\n",
        "\n",
        "# Create train/validation split\n",
        "torch.manual_seed(42) # for reproducability\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 1024\n",
        "num_epochs = 30\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Create data loader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "id": "rsVqGGs-mmny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGNet(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(EEGNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "        self.classifier = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "w49ivIFxgDzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, loss function, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EEGNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "2cVMVXpUgIzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss == None:\n",
        "            self.best_loss = val_loss\n",
        "        elif self.best_loss - val_loss > self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        elif self.best_loss - val_loss < self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True"
      ],
      "metadata": {
        "id": "239xTnB76wc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECKPOINT RETRIEVAL\n",
        "# # Load the checkpoint\n",
        "# checkpoint = torch.load('checkpoints/checkpoint_epoch_4.pt')\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# # Restore optimizer state\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# # Restore scaler state (for mixed precision training)\n",
        "# scaler.load_state_dict(checkpoint['scaler'])\n",
        "\n",
        "# # Set the starting epoch\n",
        "# start_epoch = checkpoint['epoch'] + 1\n",
        "\n",
        "# # Restore best validation loss and history\n",
        "# best_val_loss = checkpoint['best_val_loss']\n",
        "# train_losses = checkpoint['train_losses']\n",
        "# val_losses = checkpoint['val_losses']\n",
        "# val_accuracies = checkpoint['val_accuracies']\n",
        "\n",
        "# print(f\"Resuming training from epoch {start_epoch}\")\n",
        "\n",
        "# for epoch in range(start_epoch, num_epochs):"
      ],
      "metadata": {
        "id": "Z-kQHSsTAmBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss = np.inf\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "# early stopping\n",
        "early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
        "\n",
        "# checkpoint\n",
        "checkpoint_dir = 'checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # average validation loss and accuracy for this epoch\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    val_accuracy = 100. * correct / total\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    # save checkpoint\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scaler': scaler.state_dict(),\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'val_accuracies': val_accuracies,\n",
        "        'best_val_loss': best_val_loss\n",
        "    }\n",
        "    torch.save(checkpoint, f'{checkpoint_dir}/checkpoint_epoch_{epoch+1}.pt')\n",
        "\n",
        "    # save the best model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(checkpoint, f'{checkpoint_dir}/best_model.pt')\n",
        "        save_file(model.state_dict(), \"eeg_classifier.safetensors\")\n",
        "        print(f\"Saved new best model with validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, '\n",
        "          f'Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "    early_stopping(avg_val_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "print(\"Training finished!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znqLgbZ4gZ81",
        "outputId": "89d49162-70b5-473b-9f7a-89d1a59c4575"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-a530376c4980>:21: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved new best model with validation loss: 0.2612\n",
            "Epoch [1/30], Train Loss: 0.3230, Val Loss: 0.2612, Val Accuracy: 93.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, num_epochs + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(epochs, train_losses, label='Train Loss')\n",
        "plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot validation accuracy\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "h6gLnQoF3HTG",
        "outputId": "533deea5-3f5a-4a45-f647-dec47fc63548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "x and y must have same first dimension, but have shapes (30,) and (12,)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-fe6888bcc0ad>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Plot training and validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training and Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (30,) and (12,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save safetensors\n",
        "model_state_dict = model.state_dict()\n",
        "save_file(model_state_dict, \"eeg_classifier.safetensors\")\n",
        "torch.save(model, 'eeg_classifier.pth')"
      ],
      "metadata": {
        "id": "mCxAh_CDgcWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "model.load_state_dict(torch.load('path_to_your_model.pth'))\n",
        "\n",
        "torch.save(model, 'eeg_classifier_full.pth')\n",
        "save_file(model.state_dict(), \"eeg_classifier.safetensors\")\n",
        "\n",
        "def get_model_info(model):\n",
        "    return {\n",
        "        'class_name': model.__class__.__name__,\n",
        "        'layers': [\n",
        "            {\n",
        "                'name': name,\n",
        "                'type': str(type(module).__name__),\n",
        "                'parameters': {k: v.tolist() if isinstance(v, torch.Size) else v\n",
        "                               for k, v in module.__dict__.items() if not k.startswith('_')}\n",
        "            } for name, module in model.named_modules() if not isinstance(module, torch.nn.Sequential)\n",
        "        ]\n",
        "    }\n",
        "\n",
        "model_info = get_model_info(model)\n",
        "with open('config.json', 'w') as f:\n",
        "    json.dump(model_info, f, indent=2)"
      ],
      "metadata": {
        "id": "cx4YmjO-B8kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "dataset = load_dataset(\"JLB-JLB/seizure_eeg_eval\")\n",
        "\n",
        "def create_balanced_dataset(dataset, num_samples_per_class=500):\n",
        "    balanced_data = {\n",
        "        'image': [],\n",
        "        'label': []\n",
        "    }\n",
        "\n",
        "    for label in [0, 1, 2]:  # Assuming 3 classes\n",
        "        class_data = [item for item in dataset['train'] if item['label'] == label]\n",
        "        selected_data = class_data[:num_samples_per_class]\n",
        "\n",
        "        balanced_data['image'].extend([item['image'] for item in selected_data])\n",
        "        balanced_data['label'].extend([item['label'] for item in selected_data])\n",
        "\n",
        "    return balanced_data\n",
        "\n",
        "balanced_test_data = create_balanced_dataset(dataset)\n",
        "balanced_test_dataset = SeizureEEGDataset(balanced_test_data, split='train', transform=transform)\n",
        "balanced_test_dataloader = DataLoader(balanced_test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# evaluation\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "class_correct = [0, 0, 0]\n",
        "class_total = [0, 0, 0]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in balanced_test_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += (predicted[i] == label).item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "accuracy = (total_correct / total_samples) * 100\n",
        "print(f'Balanced Test Set Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "for i in range(3):\n",
        "    class_accuracy = 100 * class_correct[i] / class_total[i]\n",
        "    print(f'Accuracy of class {i}: {class_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4atEeQSw2_R",
        "outputId": "85af612d-eadb-4284-d504-6abeac859862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in balanced_test_dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rs70vQpi_vEO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}